#!/usr/bin/env python3
"""
Utility functions for the Data Engine application
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import cv2
import numpy as np
import torch


def mask_to_polygon(
    mask: np.ndarray, epsilon_factor: float = 0.01
) -> List[List[float]]:
    """
    Convert a binary mask to polygon coordinates in YOLO format

    Args:
        mask: Binary mask as numpy array
        epsilon_factor: Factor for polygon approximation (smaller = more precise)

    Returns:
        List of normalized coordinates [x1, y1, x2, y2, ...]
    """
    # Find contours
    contours, _ = cv2.findContours(
        mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
    )

    if not contours:
        return []

    # Get the largest contour
    largest_contour = max(contours, key=cv2.contourArea)

    # Approximate polygon to reduce points
    epsilon = epsilon_factor * cv2.arcLength(largest_contour, True)
    approx_polygon = cv2.approxPolyDP(largest_contour, epsilon, True)

    # Extract coordinates and normalize
    h, w = mask.shape
    normalized_coords = []

    for point in approx_polygon:
        x, y = point[0]
        normalized_coords.extend([x / w, y / h])

    return normalized_coords


def polygon_to_mask(
    polygon: List[float], img_height: int, img_width: int
) -> np.ndarray:
    """
    Convert polygon coordinates to binary mask

    Args:
        polygon: List of normalized coordinates [x1, y1, x2, y2, ...]
        img_height: Image height
        img_width: Image width

    Returns:
        Binary mask as numpy array
    """
    # Convert normalized coordinates back to pixel coordinates
    points = []
    for i in range(0, len(polygon), 2):
        x = int(polygon[i] * img_width)
        y = int(polygon[i + 1] * img_height)
        points.append([x, y])

    # Create mask
    mask = np.zeros((img_height, img_width), dtype=np.uint8)
    if len(points) >= 3:
        cv2.fillPoly(mask, [np.array(points, dtype=np.int32)], 255)

    return mask


def save_project_config(config: Dict, config_path: str):
    """Save project configuration to JSON file"""
    with open(config_path, "w") as f:
        json.dump(config, f, indent=2)


def load_project_config(config_path: str) -> Dict:
    """Load project configuration from JSON file"""
    if os.path.exists(config_path):
        with open(config_path, "r") as f:
            return json.load(f)
    return {}


def create_yolo_yaml(classes: Dict[int, str], dataset_path: str) -> str:
    """
    Create YOLO dataset YAML configuration file

    Args:
        classes: Dictionary mapping class IDs to class names
        dataset_path: Path to the dataset directory

    Returns:
        Path to the created YAML file
    """
    yaml_content = f"""# YOLO Dataset Configuration
# Generated by SAM2 Data Engine

path: {dataset_path}  # dataset root dir
train: images  # train images (relative to 'path')
val: images    # val images (relative to 'path')
test:  # test images (optional)

# Classes
nc: {len(classes)}  # number of classes
names: {list(classes.values())}  # class names
"""

    yaml_path = Path(dataset_path) / "dataset.yaml"
    with open(yaml_path, "w") as f:
        f.write(yaml_content)

    return str(yaml_path)


def validate_yolo_annotation(
    annotation_line: str, img_width: int, img_height: int
) -> bool:
    """
    Validate a YOLO annotation line

    Args:
        annotation_line: YOLO format annotation string
        img_width: Image width
        img_height: Image height

    Returns:
        True if annotation is valid
    """
    try:
        parts = annotation_line.strip().split()
        if len(parts) < 7:  # class_id + at least 3 coordinate pairs
            return False

        # Check class ID
        class_id = int(parts[0])
        if class_id < 0:
            return False

        # Check coordinates
        coords = [float(x) for x in parts[1:]]
        if len(coords) % 2 != 0:  # Must be pairs
            return False

        # Check coordinate bounds
        for i in range(0, len(coords), 2):
            x, y = coords[i], coords[i + 1]
            if not (0 <= x <= 1 and 0 <= y <= 1):
                return False

        return True

    except (ValueError, IndexError):
        return False


def calculate_mask_area(mask: np.ndarray) -> float:
    """Calculate the area of a binary mask as percentage of image"""
    total_pixels = mask.shape[0] * mask.shape[1]
    mask_pixels = np.sum(mask > 0)
    return (mask_pixels / total_pixels) * 100


def get_mask_bbox(mask: np.ndarray) -> Tuple[int, int, int, int]:
    """
    Get bounding box coordinates from binary mask

    Returns:
        Tuple of (x_min, y_min, x_max, y_max)
    """
    rows = np.any(mask, axis=1)
    cols = np.any(mask, axis=0)

    if not np.any(rows) or not np.any(cols):
        return (0, 0, 0, 0)

    y_min, y_max = np.where(rows)[0][[0, -1]]
    x_min, x_max = np.where(cols)[0][[0, -1]]

    return (x_min, y_min, x_max, y_max)


def resize_mask(mask: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
    """
    Resize a binary mask to target size

    Args:
        mask: Binary mask
        target_size: (width, height)

    Returns:
        Resized mask
    """
    return cv2.resize(
        mask.astype(np.uint8), target_size, interpolation=cv2.INTER_NEAREST
    )


def merge_masks(masks: List[np.ndarray]) -> np.ndarray:
    """
    Merge multiple binary masks into one

    Args:
        masks: List of binary masks

    Returns:
        Merged mask
    """
    if not masks:
        return np.array([])

    result = masks[0].copy()
    for mask in masks[1:]:
        result = np.logical_or(result, mask)

    return result.astype(np.uint8)


def apply_mask_overlay(
    image: np.ndarray,
    mask: np.ndarray,
    color: Tuple[int, int, int] = (0, 255, 0),
    alpha: float = 0.5,
) -> np.ndarray:
    """
    Apply a colored mask overlay to an image

    Args:
        image: RGB image
        mask: Binary mask
        color: RGB color for the overlay
        alpha: Transparency of the overlay

    Returns:
        Image with mask overlay
    """
    overlay = image.copy()
    overlay[mask > 0] = color

    return cv2.addWeighted(image, 1 - alpha, overlay, alpha, 0)


def extract_frame_info(video_path: str) -> Dict:
    """
    Extract information from video file

    Args:
        video_path: Path to video file

    Returns:
        Dictionary with video information
    """
    cap = cv2.VideoCapture(video_path)

    info = {
        "total_frames": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),
        "fps": cap.get(cv2.CAP_PROP_FPS),
        "width": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
        "height": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
        "duration": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) / cap.get(cv2.CAP_PROP_FPS)
        if cap.get(cv2.CAP_PROP_FPS) > 0
        else 0,
    }

    cap.release()
    return info


def create_directory_structure(base_path: str) -> Dict[str, str]:
    """
    Create the directory structure for the data engine project

    Args:
        base_path: Base directory path

    Returns:
        Dictionary mapping folder names to paths
    """
    base_path = Path(base_path)

    directories = {
        "cache": base_path / "cache",
        "frames": base_path / "cache" / "frames",
        "masks": base_path / "cache" / "masks",
        "features": base_path / "cache" / "features",
        "yolo_dataset": base_path / "yolo_dataset",
        "images": base_path / "yolo_dataset" / "images",
        "labels": base_path / "yolo_dataset" / "labels",
        "configs": base_path / "configs",
        "exports": base_path / "exports",
    }

    # Create all directories
    for dir_path in directories.values():
        dir_path.mkdir(parents=True, exist_ok=True)

    return {name: str(path) for name, path in directories.items()}


def cleanup_cache(cache_dir: str, keep_recent: int = 100):
    """
    Clean up old cache files, keeping only the most recent ones

    Args:
        cache_dir: Path to cache directory
        keep_recent: Number of recent files to keep
    """
    cache_path = Path(cache_dir)
    if not cache_path.exists():
        return

    # Get all files sorted by modification time
    files = sorted(cache_path.glob("*"), key=lambda x: x.stat().st_mtime, reverse=True)

    # Remove old files
    for file_path in files[keep_recent:]:
        try:
            file_path.unlink()
        except OSError:
            pass  # Ignore errors


def export_statistics(annotations: Dict, output_path: str):
    """
    Export annotation statistics to JSON file

    Args:
        annotations: Dictionary of annotations by frame
        output_path: Path to output JSON file
    """
    stats = {
        "total_frames": len(annotations),
        "total_annotations": sum(len(anns) for anns in annotations.values()),
        "annotations_per_frame": {
            str(frame_idx): len(anns) for frame_idx, anns in annotations.items()
        },
        "class_distribution": {},
        "average_annotations_per_frame": sum(len(anns) for anns in annotations.values())
        / len(annotations)
        if annotations
        else 0,
    }

    # Calculate class distribution
    for frame_annotations in annotations.values():
        for annotation in frame_annotations:
            class_id = annotation.get("class_id", "unknown")
            class_name = annotation.get("class_name", "unknown")
            key = f"{class_id}_{class_name}"
            stats["class_distribution"][key] = (
                stats["class_distribution"].get(key, 0) + 1
            )

    with open(output_path, "w") as f:
        json.dump(stats, f, indent=2)
